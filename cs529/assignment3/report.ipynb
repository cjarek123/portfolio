{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "CS529\n",
    "\n",
    "Adrien Clay\n",
    "\n",
    "Christopher Jarek\n",
    "\n",
    "Thomas Hynes\n",
    "\n",
    "Refat Mishuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import idx2numpy\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    '''\n",
    "    Loads a model from a pickle file given the filename\n",
    "    '''\n",
    "    clf = None\n",
    "    with open(filename, 'rb') as f:\n",
    "        clf = pickle.load(f)\n",
    "        f.close()\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_images = idx2numpy.convert_from_file('./mnist/t10k-images-idx3-ubyte')\n",
    "mnist_test_labels = idx2numpy.convert_from_file('./mnist/t10k-labels-idx1-ubyte')\n",
    "mnist_test_images = mnist_test_images.reshape(mnist_test_images.shape[0], -1)\n",
    "\n",
    "fash_test_images = idx2numpy.convert_from_file('./fashion/t10k-images-idx3-ubyte')\n",
    "fash_test_labels = idx2numpy.convert_from_file('./fashion/t10k-labels-idx1-ubyte')\n",
    "fash_test_images = fash_test_images.reshape(fash_test_images.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementation\n",
    "\n",
    "For our implementation, due to computer limitations we were able to train 10,000 images on each kernel at each dimensionality reduction point (50, 100, 200). We were only able to implement approximately 4 values per hyperparameter at 3 folds each.\n",
    "\n",
    "The general process for the training loop, found in `train_loop.py` is as follows:\n",
    "\n",
    "1. For each kernel\n",
    "    - For each option for number of components:\n",
    "        - Instantiate a pipeline with a standard scaler object, PCA object, and finally the support vector machine.\n",
    "        - Provide the PCA object the number of components to use\n",
    "        - Provide the support vector machine the kernel to use\n",
    "        - Insantiate `GridSearchCV` with the appropriate param grid for the training loop in question (eg. only provide the hyperparameters that each kernel acknowledges)\n",
    "        - Collect the best hyper parameters and scores from the resulting estimators and record them\n",
    "        - Test the best estimator on the test images and record this score separately\n",
    "        - Output CSV's of the results with the appropriate settings for these models\n",
    "\n",
    "### Train Loop Usage:\n",
    "\n",
    "1. Directory structure must match the following:\n",
    "```\n",
    ".\n",
    "|-- mnist/\n",
    "|   |-- t10k-images-idx3-ubyte\n",
    "|   |-- t10k-labels-idx1-ubyte\n",
    "|   |-- train-images-idx3-ubyte\n",
    "|   `-- train-labels-idx1-ubyte\n",
    "|-- fashion/\n",
    "|   |-- t10k-images-idx3-ubyte\n",
    "|   |-- t10k-labels-idx1-ubyte\n",
    "|   |-- train-images-idx3-ubyte\n",
    "|   `-- train-labels-idx1-ubyte\n",
    "`-- train_loop.py\n",
    "```\n",
    "\n",
    "2. Call `python ./train_loop.py`\n",
    "\n",
    "3. Enter the number of samples to train on. We used 10,000.\n",
    "\n",
    "4. The model results will be saved as pickle files in `./models`, a newly created folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Settings\n",
    "\n",
    "The search space for the models was defined as follows:\n",
    "\n",
    "1. Linear Kernel:\n",
    "    - C parameter: [.001, .01, .1, 1]\n",
    "2. RBF Kernel:\n",
    "    - C parameter: [.001, .01, .1, 1]\n",
    "    - Gamma parameter: [.0001, .001, .01, .1]\n",
    "3. Poly Kernel:\n",
    "    - C parameter: [.001, .01, .1, 1]\n",
    "    - Gamma Parameter: [.0001, .001, .01, .1]\n",
    "    - Degree Parameter: [1,2,3,4]\n",
    "\n",
    "The reason for our constraint was due to number of fits required by each step in the Grid Search. For example, the number of fits if we had used 8 hyperparamters and five folds for the polynomial kernel would have result in:\n",
    "\n",
    "$$\n",
    "8^3 * 5 = 2560\n",
    "$$\n",
    "<center>\n",
    "That is, 2560 fits on 60,000 images, doubled since there are two datasets.\n",
    "</center>\n",
    "\n",
    "In order to satisfy computer constraints, we used 10,000 images with four hyperparameters each, trained on 3 folds, so `cv=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('minst_train_result.csv')\n",
    "mnist_fash = pd.read_csv('mnist_fashion_train_result.csv')\n",
    "mnist.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "mnist_fash.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Settings for MNIST: \n",
      "   n_components kernel  best_c  best_degree  best_gamma  best_score  accuracy\n",
      "8           200   poly   0.001          3.0         0.1      0.9512    0.9583\n",
      "\n",
      "Best Model Settings for MNIST Fashion\n",
      "   n_components kernel  best_c  best_degree  best_gamma  best_score  accuracy\n",
      "8           200   poly     0.1          2.0        0.01    0.863701    0.8601\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Model Settings for MNIST: \")\n",
    "print(mnist[mnist.accuracy == mnist.accuracy.max()])\n",
    "print()\n",
    "print(\"Best Model Settings for MNIST Fashion\")\n",
    "print(mnist_fash[mnist_fash.accuracy == mnist_fash.accuracy.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "From the above output we can see that the best results were both from the `poly` kernel with 200 components used in the PCA reduction.\n",
    "\n",
    "1. For MNIST:\n",
    "    - Components: 100\n",
    "    - C: 1.0\n",
    "    - Degree: 3.0\n",
    "    - Gamma: 0.01\n",
    "    - Resulting Accuracy: ~95%\n",
    "\n",
    "2. For MNIST Fashion:\n",
    "    - Components: 200\n",
    "    - C: .1\n",
    "    - Degree: 2.0\n",
    "    - Gamma: .01\n",
    "    - Resulting Accuracy: ~86%\n",
    "\n",
    "Overall, these are pretty decent scores for the dataset considering only 1/6 of the images were used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Comparisons\n",
    "\n",
    "Below are the two tables for MNIST and MNIST fashion respectively.\n",
    "\n",
    "In general, the scores are lower for the MNIST Fashion set, but are overall acceptably high.\n",
    "\n",
    "Although the best_score column for mnist goes to the poly kernel with 100 components, the highest accuracy in testing went to 200 components in the poly kernel, so we have used this for demonstration going forward.\n",
    "\n",
    "The performance of the kernels in both datasets seem to follow a similar pattern, that is, as the number of components increases, the score/accuracy also increase. Incidentally, the way the below tables are structure further demonstrates this pattern as we can see an increase in accuracy as we move from linear to rbf, and finally to poly, with poly being the most well performing kernel amongst all three kernels, and 200 components being the highest performing number of components of the available options 50, 100 and 200.\n",
    "\n",
    "Because of the differences in kernels, we can most likely conclude that the poly kernel does so well because the datasets benefit from the polynomial nature of the 'poly' kernel, such that non-linear decision boundaries are causing accuracy to increase. Although the linear kernel performs acceptably high, it is clear that the polynomial space provided by the 'poly` kernel is of benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>kernel</th>\n",
       "      <th>best_c</th>\n",
       "      <th>best_degree</th>\n",
       "      <th>best_gamma</th>\n",
       "      <th>best_score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.9201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>0.9311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>0.9366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>0.9411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>poly</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.9543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.9583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_components  kernel  best_c  best_degree  best_gamma  best_score  accuracy\n",
       "0            50  linear   0.010          NaN         NaN      0.9186    0.9201\n",
       "1           100  linear   0.010          NaN         NaN      0.9230    0.9250\n",
       "2           200  linear   0.010          NaN         NaN      0.9252    0.9311\n",
       "3            50     rbf   1.000          NaN       0.001      0.9325    0.9366\n",
       "4           100     rbf   1.000          NaN       0.001      0.9345    0.9411\n",
       "5           200     rbf   1.000          NaN       0.001      0.9334    0.9421\n",
       "6            50    poly   0.100          3.0       0.010      0.9444    0.9506\n",
       "7           100    poly   1.000          3.0       0.010      0.9517    0.9543\n",
       "8           200    poly   0.001          3.0       0.100      0.9512    0.9583"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>kernel</th>\n",
       "      <th>best_c</th>\n",
       "      <th>best_degree</th>\n",
       "      <th>best_gamma</th>\n",
       "      <th>best_score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835600</td>\n",
       "      <td>0.8245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.845400</td>\n",
       "      <td>0.8397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.8407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.839600</td>\n",
       "      <td>0.8376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.846600</td>\n",
       "      <td>0.8455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.851100</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.8489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.863501</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.863701</td>\n",
       "      <td>0.8601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_components  kernel  best_c  best_degree  best_gamma  best_score  accuracy\n",
       "0            50  linear   0.010          NaN         NaN    0.835600    0.8245\n",
       "1           100  linear   0.010          NaN         NaN    0.845400    0.8397\n",
       "2           200  linear   0.010          NaN         NaN    0.844000    0.8407\n",
       "3            50     rbf   1.000          NaN       0.001    0.839600    0.8376\n",
       "4           100     rbf   1.000          NaN       0.001    0.846600    0.8455\n",
       "5           200     rbf   1.000          NaN       0.001    0.851100    0.8503\n",
       "6            50    poly   0.010          2.0       0.100    0.857500    0.8489\n",
       "7           100    poly   0.001          2.0       0.100    0.863501    0.8565\n",
       "8           200    poly   0.100          2.0       0.010    0.863701    0.8601"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_fash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results & Confusion Matrices\n",
    "\n",
    "Below are the results of the models using the test images from each dataset to reproduce the prediction results obtained from the grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_best = load_model('./models/MNIST_poly_n_200.pkl')\n",
    "preds = mnist_best.predict(mnist_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 962    0    5    2    0    1    5    1    4    0]\n",
      " [   0 1124    2    2    1    1    4    0    1    0]\n",
      " [   5    1  982    5    6    1    4    6   20    2]\n",
      " [   0    0   10  966    3    7    0    5   17    2]\n",
      " [   0    2    6    2  952    1    3    3    4    9]\n",
      " [   5    0    3   14    3  836    5    0   22    4]\n",
      " [   5    3    6    1   10    8  919    0    6    0]\n",
      " [   1    6   13    2   11    0    0  973    4   18]\n",
      " [   5    1    8    6    8   13    1    3  925    4]\n",
      " [   5    3    1    6   22    5    0    7   16  944]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.95      0.95      0.95      1032\n",
      "           3       0.96      0.96      0.96      1010\n",
      "           4       0.94      0.97      0.95       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.98      0.96      0.97       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.91      0.95      0.93       974\n",
      "           9       0.96      0.94      0.95      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print()\n",
    "print(confusion_matrix(mnist_test_labels, preds))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(mnist_test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "We can see from the confusion matrix that the model scores a high number of true-positives. This is further confirmed by the precision and recall scores from the classification report.\n",
    "\n",
    "In general, the data is highly classifiable in that the model is having an easy time distinguishing classes with low ambiguity between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[791   2  20  40   2   0 135   1   9   0]\n",
      " [  3 955   7  27   5   0   3   0   0   0]\n",
      " [ 12   3 782  17 106   0  75   2   3   0]\n",
      " [ 24   4  14 890  27   0  39   0   2   0]\n",
      " [  1   0 111  33 766   1  84   1   3   0]\n",
      " [  0   0   1   2   0 921   2  48   2  24]\n",
      " [118   1 105  39  76   0 647   0  14   0]\n",
      " [  0   0   0   0   0  17   0 960   0  23]\n",
      " [  1   1   8  10   6   7  17   5 945   0]\n",
      " [  0   1   0   1   0  10   0  43   1 944]]\n"
     ]
    }
   ],
   "source": [
    "m_fashion_best = load_model('./models/MNIST_FASH_poly_n_200.pkl')\n",
    "preds = m_fashion_best.predict(fash_test_images)\n",
    "print(\"Confusion Matrix\")\n",
    "print()\n",
    "print(confusion_matrix(fash_test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1000\n",
      "           1       0.99      0.95      0.97      1000\n",
      "           2       0.75      0.78      0.76      1000\n",
      "           3       0.84      0.89      0.86      1000\n",
      "           4       0.78      0.77      0.77      1000\n",
      "           5       0.96      0.92      0.94      1000\n",
      "           6       0.65      0.65      0.65      1000\n",
      "           7       0.91      0.96      0.93      1000\n",
      "           8       0.97      0.94      0.96      1000\n",
      "           9       0.95      0.94      0.95      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(classification_report(fash_test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Similarly to the MNIST dataset, the confusion matrix and classification report for the dataset implies a higher level of classifiability, in that the features are easy enough to distinguish with a low level ambiguity. The strong diagonal in the confusion matrix implies a high level of true positives.\n",
    "\n",
    "However, in the MNIST Fashion dataset we can see that the model has some difficulty distinguishing classes 2, 4 and 6 specifically.\n",
    "\n",
    "In the below figure, we compare the images from classes zero and one to the images from classes two, four, and six. We can see it might be the case that the model has trouble distinguishing shirt-like objects with longer sleeves. It's relatively clear why it might not have a difficult time distinguishing the pair of pants from class one, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '6')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fash_normal = idx2numpy.convert_from_file('./fashion/t10k-images-idx3-ubyte')\n",
    "class_0 = [i for i in range(len(fash_test_labels)) if fash_test_labels[i] == 0][0]\n",
    "class_1 = [i for i in range(len(fash_test_labels)) if fash_test_labels[i] == 1][0]\n",
    "class_2 = [i for i in range(len(fash_test_labels)) if fash_test_labels[i] == 2][0]\n",
    "class_4 = [i for i in range(len(fash_test_labels)) if fash_test_labels[i] == 4][0]\n",
    "class_6 = [i for i in range(len(fash_test_labels)) if fash_test_labels[i] == 6][0]\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5)\n",
    "fig.suptitle(\"Class Comparison\")\n",
    "ax1.imshow(fash_normal[class_0])\n",
    "ax1.set_title(\"0\")\n",
    "ax2.imshow(fash_normal[class_1])\n",
    "ax2.set_title(\"1\")\n",
    "ax3.imshow(fash_normal[class_2])\n",
    "ax3.set_title(\"2\")\n",
    "ax4.imshow(fash_normal[class_4])\n",
    "ax4.set_title(\"4\")\n",
    "ax5.imshow(fash_normal[class_6])\n",
    "ax5.set_title(\"6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Announcment:\n",
    "\n",
    ">In Task 3.2, you are required to use PCA and LDA to find the principal components of the numbers k = 50, 100 and 200. Theoretically, you may choose any k which is less than the number of original features using Fisher's algorithm presented in our slides and textbook. However, the scikit-learn class LinearDiscriminantAnalysis bounds the value of k by L-1 where L is the number of classes.\n",
    "\n",
    " \n",
    "\n",
    "> 1. Why scikit-learn does so?\n",
    "\n",
    "> 2. Usually considering less than L - 1 features may lead to a very bad accuracy. Then, how can we come up with a learning framework to consider more than L - 1 meaningful principle components (reduced features) using LDA?\n",
    "\n",
    "> 3. How can we get rid of any upper limit (less than the number of original features) of the number of meaningful principle components?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scikit-learn imposes this restriction because of the way separating hyperplanes are found between classes. For example, when you separate two classes, you can find one hyperplane, so one discriminant function is enough. To separate more than one for $L$ classes, $L-1$ discriminant functions will be enough.\n",
    "\n",
    "    See [Discriminant Functions][discrminant_functions]\n",
    "2. Potentially, one could utilize LDA for more features if you applied PCA first, followed by LDA. PCA will assist with noise reduction and preservation of important information, while LDA will maximize the class separation. This is sort of a roundabout way of allowing 'more' classis into the Linear Discriminant Analysis, as you will preserve important information via PCA, allowing you to include 'more' in the LDA in a very indirect way.\n",
    "\n",
    "3. Similarly to answer 2, you might be able to get rid of any upper limit by reducing the number of features with PCA initially, allowing you to fit 'more' in the LDA without a class limit. Alternatively, one could potentially use feature extraction to extract more features, allowing you to increase `n_components` in LDA according to the number of new features.\n",
    "\n",
    "[discrminant_functions]: https://en.wikipedia.org/wiki/Linear_discriminant_analysis#Discriminant_functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
