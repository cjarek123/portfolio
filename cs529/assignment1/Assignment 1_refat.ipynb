{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Loss: [4, 3, 2, 3, 2, 3, 1, 0, 0, 0]\n",
      "Number of updates in Perceptron: 7\n",
      "Perceptron Margin: 1.718363763129416\n",
      "For Perceptron converged in weight  [-0.00175655  0.00538244]  & bias  -0.006\n",
      "AdalineGD Loss:           0\n",
      "0  0.434769\n",
      "1  0.394333\n",
      "2  0.360073\n",
      "3  0.331027\n",
      "4  0.306386\n",
      "5  0.285465\n",
      "6  0.267688\n",
      "7  0.252565\n",
      "8  0.239685\n",
      "9  0.228699\n",
      "Number of updates in AdalineGD: 10\n",
      "AdalineGD Margin: 4.472517997318707\n",
      "For AdalineGD converged in weight  [0.05138196 0.02315132]  & bias  0.005647942224158802\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "class Perceptron:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.float64(0.)\n",
    "        self.errors_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
    "s='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df=pd.read_csv(s, header=None, encoding='utf-8')\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "ppn = Perceptron(eta=0.001, n_iter=10)\n",
    "ppn.fit(X, y)\n",
    "print('Perceptron Loss:',ppn.errors_)\n",
    "print('Number of updates in Perceptron:',ppn.n_iter-ppn.errors_.count(0))\n",
    "margin=abs(np.min((np.dot(X, ppn.w_)+ppn.b_)/np.linalg.norm(ppn.w_)))\n",
    "print('Perceptron Margin:',margin)\n",
    "print('For Perceptron converged in weight ',ppn.w_,' & bias ',ppn.b_)\n",
    "class AdalineGD:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.float64(0.)\n",
    "        self.losses_ = []\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_ += self.eta * 2.0 * X.T.dot(errors) / X.shape[0]\n",
    "            self.b_ += self.eta * 2.0 * errors.mean()\n",
    "            loss = (errors**2).mean()\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def activation(self, X):\n",
    "        return X\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(self.net_input(X))>= 0.5, 1, 0)\n",
    "s='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df=pd.read_csv(s, header=None, encoding='utf-8')\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "agd = AdalineGD(eta=0.001, n_iter=10)\n",
    "agd.fit(X, y)\n",
    "df = pd.DataFrame(agd.losses_)\n",
    "print('AdalineGD Loss:',df)\n",
    "print('Number of updates in AdalineGD:',agd.n_iter-agd.losses_.count(0))\n",
    "margin=abs(np.min((np.dot(X, agd.w_)+agd.b_)/np.linalg.norm(agd.w_)))\n",
    "print('AdalineGD Margin:',margin)\n",
    "print('For AdalineGD converged in weight ',agd.w_,' & bias ',agd.b_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function\n",
    "\n",
    "In perceptron learning, Loss = $\\sum_{n=1}^{n=100}{(y_i - y\\hat{i})} $\n",
    "\n",
    "In Adaline, Loss = $\\frac{1}{n}\\sum_{n=1}^{n=100}{(y_i - \\hat{y}_i)^2} $\n",
    "\n",
    "Number of updates\n",
    "\n",
    "Number of updates = Number of iteration - Number of non-zero loss function. \n",
    "In perceptron number of nonzero loss function is 3, resulting number of updates = 10-3 =7\n",
    "\n",
    "In case of Adaline, there is no nonzero loss function resulting number of update = 10-0=10\n",
    "\n",
    "Margin\n",
    "\n",
    "The margin refers to the distance between the decision boundary and the nearest data point. A larger margin typically indicates better generalization.\n",
    "So, margin = $\\min {\\frac{W^Tx+b}{|W|}} $. \n",
    "In case of Perceptron, $ W=W_j+\\Delta W_j=W_j+\\eta(y_i-\\hat{y}_i)x_j $. So, The Perceptron does not try to find the decision boundary that maximizes the margin.\n",
    "\n",
    "In case of Adaline, $ W=W_j+\\Delta W_j=W_j-\\eta\\frac{\\partial L}{\\partial W_j} $. As Adaline directly minimizes the error across all data points, the margin is higher. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
